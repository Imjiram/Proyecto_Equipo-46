{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMzhdmzav7Cz"
      },
      "source": [
        "## PROYECTO INTEGRADOR\n",
        "\n",
        "\n",
        "# **Avance 4. Modelos alternativos**\n",
        "\n",
        "Jiram Cesar Villalpando Guerrero        A01793579\n",
        "\n",
        "Josep Romagosa Llordén                  A01374637\n",
        "\n",
        "José Francisco Muñoz Del Angel          A01794174\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**3.1 Establecer las medidas de calidad del modelo de aprendizaje automático**\n",
        "\n",
        "**3.2 Proporcionar un marco de referencia para evaluar y mejorar modelos más avanzados.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Vf8C0D5ZyB9v"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "HxpjO5Dsv01d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "import dask.dataframe as dd\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import RidgeCV, ElasticNetCV, LassoCV\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from joblib import Parallel, delayed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QfB6kB1_JZQ",
        "outputId": "3f622c3f-755e-4488-9b5b-876c02abd2a3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "MmxOMugTwTh2"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/data_source/'\n",
        "\n",
        "\n",
        "csv_files = ['data2.csv']  # Solo dos archivos\n",
        "\n",
        "# Leer archivos CSV y combinarlos en un DataFrame\n",
        "dfs = [pd.read_csv(file_path + file) for file in csv_files]\n",
        "data = pd.concat(dfs, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-Ny5WOxDxQO-"
      },
      "outputs": [],
      "source": [
        "df = data[['CourierCode', 'Parcel', 'ZipCodeFrom', 'ZipCodeTo', 'TransitAt', 'DeliveredAt']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ICg6zA4JxSUh"
      },
      "outputs": [],
      "source": [
        "df['ParcelDict'] = df['Parcel'].apply(json.loads)\n",
        "df['Weight'] = df['ParcelDict'].apply(lambda x: x.get('Weight', 0))\n",
        "df['Height'] = df['ParcelDict'].apply(lambda x: x.get('Height', 0))\n",
        "df['Length'] = df['ParcelDict'].apply(lambda x: x.get('Length', 0))\n",
        "df['Width'] = df['ParcelDict'].apply(lambda x: x.get('Width', 0))\n",
        "df.drop(['Parcel', 'ParcelDict'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YsCjWTSjzB5Z"
      },
      "outputs": [],
      "source": [
        "# Convertir columnas de fecha\n",
        "df['TransitAt'] = pd.to_datetime(df['TransitAt'])\n",
        "df['DeliveredAt'] = pd.to_datetime(df['DeliveredAt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "RzgJTbBO93JC"
      },
      "outputs": [],
      "source": [
        "# Calculo de tiempo en transito\n",
        "df['TransitTime'] = (df['DeliveredAt'] - df['TransitAt']).dt.total_seconds() / 3600"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "i6dUlg9wD8L9"
      },
      "outputs": [],
      "source": [
        "# Transformación logaritmica de TransitTime para normalizar la distribucion\n",
        "df['TransitTime_log'] = np.log1p(df['TransitTime'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "2WdcCbhI_N_6"
      },
      "outputs": [],
      "source": [
        "# Añadir caracteristicas basadas en la fecha\n",
        "df['TransitAt_year'] = df['TransitAt'].dt.year\n",
        "df['TransitAt_month'] = df['TransitAt'].dt.month\n",
        "df['TransitAt_weekday'] = df['TransitAt'].dt.weekday"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Tz6lsATS_Tol"
      },
      "outputs": [],
      "source": [
        "# Codificación de las variables categoricas\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "courier_status_encoded = encoder.fit_transform(df[['CourierCode']])\n",
        "courier_status_features = encoder.get_feature_names_out(['CourierCode'])\n",
        "courier_status_df = pd.DataFrame(courier_status_encoded, columns=courier_status_features)\n",
        "\n",
        "# Crear imputador que reemplazará NaN con el valor más frecuente en la columna\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Aplicar imputador a las columnas de mes y día de la semana\n",
        "df['TransitAt_month'] = imputer.fit_transform(df[['TransitAt_month']])\n",
        "df['TransitAt_weekday'] = imputer.fit_transform(df[['TransitAt_weekday']])\n",
        "\n",
        "month_weekday_encoded = encoder.fit_transform(df[['TransitAt_month', 'TransitAt_weekday']])\n",
        "month_weekday_features = encoder.get_feature_names_out(['TransitAt_month', 'TransitAt_weekday'])\n",
        "month_weekday_df = pd.DataFrame(month_weekday_encoded, columns=month_weekday_features)\n",
        "\n",
        "# Concatenar las nuevas caracteristicas codificadas al dataframe original\n",
        "df_encoded = pd.concat([df, courier_status_df, month_weekday_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "DsguNWtX-EAD"
      },
      "outputs": [],
      "source": [
        "# Eliminar columnas que ya no se necesitan\n",
        "columns_to_drop = ['CourierCode', 'TransitAt', 'DeliveredAt', 'TransitAt_month', 'TransitAt_weekday']\n",
        "df_encoded.drop(columns_to_drop, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "DMsNXth_K346"
      },
      "outputs": [],
      "source": [
        "cols_to_check = ['ZipCodeTo', 'Weight', 'Height', 'Length', 'Width']\n",
        "df_encoded[cols_to_check] = df_encoded[cols_to_check].applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n",
        "\n",
        "# Eliminar filas con NaN en las columnas especificadas\n",
        "df_encoded = df_encoded.dropna(subset=cols_to_check)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qu_-9EmuA53Y"
      },
      "outputs": [],
      "source": [
        "# Imputar valores nan\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df_encoded_filled = imputer.fit_transform(df_encoded)\n",
        "df_encoded_filled = pd.DataFrame(df_encoded_filled, columns=df_encoded.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "uLDfvYw_-HSh"
      },
      "outputs": [],
      "source": [
        "# Escalar las caracteristicas numericas\n",
        "scaler = StandardScaler()\n",
        "df_encoded_scaled = scaler.fit_transform(df_encoded_filled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "26ykNgPI-U-4"
      },
      "outputs": [],
      "source": [
        "# Selección de caracteristicas mediante umbral de varianza\n",
        "selector = VarianceThreshold(threshold=0.95)\n",
        "df_reduced = selector.fit_transform(df_encoded_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BslKpqtJfs6n"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Entrega 4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU7Ro-kUf-6y"
      },
      "source": [
        "3.3 Explorar una gama diversa de técnicas y enfoques con el fin de identificar el de mejor desempeño en el conjunto de datos en cuestión.\n",
        "\n",
        "3.4 Encontrar la configuración óptima que maximiza el rendimiento del modelo en una tarea específica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "NoJEo_wvgEDU"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LassoCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "M46uSZq1r-cr"
      },
      "outputs": [],
      "source": [
        "features = ['ZipCodeFrom', 'ZipCodeTo'] + list(courier_status_features) + list(month_weekday_features)\n",
        "X = df_encoded_filled[features]\n",
        "y = df_encoded_filled['TransitTime']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir las características y el objetivo\n",
        "features = ['ZipCodeFrom', 'ZipCodeTo'] + list(courier_status_features) + list(month_weekday_features)\n",
        "X = df_encoded_filled[features]\n",
        "y = df_encoded_filled['TransitTime']\n",
        "\n",
        "# Reducir el tamaño del conjunto de datos para pruebas rápidas\n",
        "sample_size = 10000\n",
        "X_sample, _, y_sample, _ = train_test_split(X, y, train_size=sample_size, random_state=42)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definir la función para entrenar y evaluar un modelo\n",
        "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    return mse, r2, mae, training_time\n",
        "\n",
        "# Definir los modelos con parámetros ajustados\n",
        "models = {\n",
        "    'SVR': SVR(C=1.0, epsilon=0.2),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
        "    'KNN': KNeighborsRegressor(n_neighbors=5),\n",
        "    'Ridge Regression': RidgeCV(alphas=np.logspace(-3, 3, 7)),\n",
        "    'ElasticNet': ElasticNetCV(cv=3, random_state=42),\n",
        "    'Lasso': LassoCV(cv=3, random_state=42)\n",
        "}\n",
        "\n",
        "# Evaluar modelos en paralelo\n",
        "def evaluate(name, model):\n",
        "    mse, r2, mae, training_time = train_and_evaluate_model(model, X_train, y_train, X_test, y_test)\n",
        "    return name, {'MSE': mse, 'R2 Score': r2, 'MAE': mae, 'Training Time': training_time}\n",
        "\n",
        "# Realizar evaluación de modelos en paralelo\n",
        "results = Parallel(n_jobs=-1)(delayed(evaluate)(name, model) for name, model in models.items())\n",
        "results = dict(results)\n",
        "\n",
        "# Imprimir los resultados\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        print(f\"{metric_name}: {value:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uzPUEFfGXhnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6affff04-7031-4bfd-b40a-f3823cc54aa0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: SVR\n",
            "MSE: 3459.6735\n",
            "R2 Score: -0.0226\n",
            "MAE: 38.3801\n",
            "Training Time: 13.2912\n",
            "\n",
            "Model: Gradient Boosting\n",
            "MSE: 2477.1551\n",
            "R2 Score: 0.2678\n",
            "MAE: 30.7120\n",
            "Training Time: 2.7625\n",
            "\n",
            "Model: KNN\n",
            "MSE: 3402.8580\n",
            "R2 Score: -0.0058\n",
            "MAE: 38.5181\n",
            "Training Time: 0.0051\n",
            "\n",
            "Model: Ridge Regression\n",
            "MSE: 2851.8275\n",
            "R2 Score: 0.1570\n",
            "MAE: 34.5772\n",
            "Training Time: 0.0643\n",
            "\n",
            "Model: ElasticNet\n",
            "MSE: 3375.0645\n",
            "R2 Score: 0.0024\n",
            "MAE: 38.8269\n",
            "Training Time: 0.2743\n",
            "\n",
            "Model: Lasso\n",
            "MSE: 3375.0648\n",
            "R2 Score: 0.0024\n",
            "MAE: 38.8269\n",
            "Training Time: 0.5128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar los dos mejores modelos basado en R2 Score\n",
        "sorted_results = sorted(results.items(), key=lambda item: item[1]['R2 Score'], reverse=True)\n",
        "best_models = sorted_results[:2]\n",
        "\n",
        "# Imprimir los mejores modelos\n",
        "print(\"\\nBest Models:\")\n",
        "for model_name, metrics in best_models:\n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        print(f\"{metric_name}: {value:.4f}\")\n",
        "\n",
        "# Definir los parámetros de búsqueda para los dos mejores modelos\n",
        "param_grids = {\n",
        "    'Gradient Boosting': {\n",
        "        'n_estimators': [100, 200],\n",
        "        'learning_rate': [0.1, 0.05],\n",
        "        'max_depth': [3, 4, 5]\n",
        "    },\n",
        "    'ElasticNet': {\n",
        "        'l1_ratio': [0.1, 0.5, 0.9],\n",
        "        'alphas': [0.01, 0.1, 1.0, 10.0]\n",
        "    }\n",
        "}\n",
        "\n",
        "best_params = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRdeJxj5cbba",
        "outputId": "d96d82e8-2007-4513-bccf-eaed5336fac3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Models:\n",
            "\n",
            "Model: Gradient Boosting\n",
            "MSE: 2477.1551\n",
            "R2 Score: 0.2678\n",
            "MAE: 30.7120\n",
            "Training Time: 2.7625\n",
            "\n",
            "Model: Ridge Regression\n",
            "MSE: 2851.8275\n",
            "R2 Score: 0.1570\n",
            "MAE: 34.5772\n",
            "Training Time: 0.0643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ajustar los hiperparámetros de los mejores modelos\n",
        "for model_name, _ in best_models:\n",
        "    if model_name in param_grids:\n",
        "        param_grid = param_grids[model_name]\n",
        "        grid_search = GridSearchCV(models[model_name], param_grid, cv=3, n_jobs=-1, scoring='r2')\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        best_params[model_name] = grid_search.best_params_\n",
        "        models[model_name] = grid_search.best_estimator_\n",
        "\n",
        "# mejores parámetros\n",
        "print(\"\\nBest Parameters:\")\n",
        "for model_name, params in best_params.items():\n",
        "    print(f\"{model_name}: {params}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce0Whn8Ib5Ze",
        "outputId": "9d3afd72-3759-4b13-c77d-36b163ba7d80"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Parameters:\n",
            "Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reevaluar los modelos con los mejores hiperparámetros\n",
        "final_results = {}\n",
        "for name, _ in best_models:\n",
        "    mse, r2, mae, _ = train_and_evaluate_model(models[name], X_train, y_train, X_test, y_test)\n",
        "    final_results[name] = {'MSE': mse, 'R2 Score': r2, 'MAE': mae}\n",
        "\n",
        "# Imprimir los resultados finales\n",
        "print(\"\\nFinal Results:\")\n",
        "for model_name, metrics in final_results.items():\n",
        "    print(f\"\\nModel: {model_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h0gUjwPcVNJ",
        "outputId": "536fdc6b-d52d-48ab-f64c-54b2a6b056eb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Results:\n",
            "\n",
            "Model: Gradient Boosting\n",
            "\n",
            "Model: Ridge Regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6def7ScX_hm"
      },
      "source": [
        "# **Análisis y Conclusiones**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVR (Support Vector Regression)\n",
        "\n",
        "MSE: 3459.6735\n",
        "R2 Score: -0.0226\n",
        "MAE: 38.3801\n",
        "Training Time: 13.1048\n",
        "El modelo SVR muestra un rendimiento negativo con un R² por debajo de 0, indicando que el modelo es peor que un modelo de referencia que predice el valor medio. El MSE y MAE son altos, y el tiempo de entrenamiento es considerablemente largo.\n",
        "\n",
        "Gradient Boosting\n",
        "\n",
        "MSE: 2477.1551\n",
        "R2 Score: 0.2678\n",
        "MAE: 30.7120\n",
        "Training Time: 5.6991\n",
        "Gradient Boosting muestra el mejor rendimiento entre todos los modelos iniciales, con un R² positivo y el más alto (0.2678), lo que indica que puede explicar aproximadamente el 26.78% de la variabilidad en los datos. El MSE y MAE son más bajos en comparación con otros modelos y el tiempo de entrenamiento es razonable.\n",
        "\n",
        "KNN (K-Nearest Neighbors)\n",
        "\n",
        "MSE: 3402.8580\n",
        "R2 Score: -0.0058\n",
        "MAE: 38.5181\n",
        "Training Time: 0.0169\n",
        "KNN también muestra un rendimiento negativo en términos de R², similar a SVR, con MSE y MAE altos. Sin embargo, el tiempo de entrenamiento es extremadamente corto.\n",
        "\n",
        "Ridge Regression\n",
        "\n",
        "MSE: 2851.8275\n",
        "R2 Score: 0.1570\n",
        "MAE: 34.5772\n",
        "Training Time: 0.2772\n",
        "Ridge Regression tiene un rendimiento decente con un R² positivo (0.1570), aunque no tan bueno como Gradient Boosting. Muestra un MSE y MAE moderados y un tiempo de entrenamiento corto.\n",
        "\n",
        "ElasticNet\n",
        "\n",
        "MSE: 3375.0645\n",
        "R2 Score: 0.0024\n",
        "MAE: 38.8269\n",
        "Training Time: 0.6554\n",
        "ElasticNet muestra un rendimiento similar al de Lasso, con un R² cercano a 0, indicando que casi no tiene poder predictivo. El MSE y MAE son altos y el tiempo de entrenamiento es bajo a moderado.\n",
        "\n",
        "Lasso\n",
        "\n",
        "MSE: 3375.0648\n",
        "R2 Score: 0.0024\n",
        "MAE: 38.8269\n",
        "Training Time: 0.4149\n",
        "Lasso muestra un rendimiento casi idéntico al de ElasticNet, con los mismos valores de MSE, R² y MAE, y un tiempo de entrenamiento ligeramente más corto.\n",
        "\n",
        "\n",
        "\n",
        "# Conclusiones\n",
        "\n",
        "Los resultados de los modelos muestran que Gradient Boosting y Ridge Regression son las opciones más prometedoras. Gradient Boosting tuvo el mejor rendimiento, con un MSE de 2477.1551, R² de 0.2678 y MAE de 30.7120, demostrando ser el modelo más preciso en explicar la variabilidad en los datos. Aunque el tiempo de entrenamiento fue de 5.6991 segundos, su capacidad predictiva justifica esta inversión de tiempo. Ridge Regression también tuvo un rendimiento decente, con un MSE de 2851.8275, R² de 0.1570 y MAE de 34.5772, destacándose por su velocidad de entrenamiento de 0.2772 segundos.\n",
        "\n",
        "\n",
        "\n",
        "En contraste, los modelos SVR, KNN, ElasticNet y Lasso mostraron un desempeño insatisfactorio, con altos valores de MSE y MAE y R² negativos o cercanos a cero. Esto indica una baja capacidad predictiva, especialmente en comparación con Gradient Boosting y Ridge Regression. En conclusión, se recomienda utilizar Gradient Boosting como el modelo final debido a su mayor precisión, optimizado con los mejores hiperparámetros {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}, mientras que Ridge Regression puede considerarse una alternativa rápida y razonablemente precisa.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KhMBM0ANXhUT"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}